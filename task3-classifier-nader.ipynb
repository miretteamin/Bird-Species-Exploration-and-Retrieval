{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EGYPT\\AppData\\Local\\Temp\\ipykernel_2536\\950852310.py:13: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  image_attribute_labels = pd.read_csv(os.path.join(data_dir, 'attributes/image_attribute_labels.txt'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_id                                          file_path\n",
      "0         1  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
      "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
      "2         3  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
      "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
      "4         5  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
      "   image_id  class_id\n",
      "0         1         1\n",
      "1         2         1\n",
      "2         3         1\n",
      "3         4         1\n",
      "4         5         1\n",
      "   class_id                  class_name\n",
      "0         1  001.Black_footed_Albatross\n",
      "1         2        002.Laysan_Albatross\n",
      "2         3         003.Sooty_Albatross\n",
      "3         4       004.Groove_billed_Ani\n",
      "4         5          005.Crested_Auklet\n",
      "(11788, 2)\n",
      "(11788, 2)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the CUB-200-2011 dataset\n",
    "def load_cub_dataset(data_dir):\n",
    "    images = pd.read_csv(os.path.join(data_dir, 'images.txt'), sep=' ', names=['image_id', 'file_path'])\n",
    "    labels = pd.read_csv(os.path.join(data_dir, 'image_class_labels.txt'), sep=' ', names=['image_id', 'class_id'])\n",
    "    classes = pd.read_csv(os.path.join(data_dir, 'classes.txt'), sep=' ', names=['class_id', 'class_name'])\n",
    "    bounding_boxes = pd.read_csv(os.path.join(data_dir, 'bounding_boxes.txt'), sep=' ', names=['image_id', 'x', 'y', 'width', 'height'])\n",
    "    part_locs = pd.read_csv(os.path.join(data_dir, 'parts/part_locs.txt'), sep=' ', names=['img_id', 'part_id', 'x', 'y', 'visible'])\n",
    "    # parts = pd.read_csv(os.path.join(data_dir, 'parts/parts.txt'), delimiter =' ', names=['part_id', 'part_name'])\n",
    "    parts = pd.read_fwf(os.path.join(data_dir, 'parts/parts.txt'), colspecs=[(0, 2), (2, None)], header=None, names=['part_id', 'part_name'])\n",
    "    parts_click_locs = pd.read_csv(os.path.join(data_dir, 'parts/part_click_locs.txt'), sep = ' ', names=['image_id', 'part_id', 'x', 'y', 'visible', 'time'])\n",
    "    attributes = pd.read_csv(os.path.join(data_dir, 'attributes/attributes.txt'), sep = ' ', names=['attribute_id', 'attribute_name'])\n",
    "    certainties = pd.read_fwf(os.path.join(data_dir, 'attributes/certainties.txt'), colspecs=[(0, 1), (2, None)], names=[\"certainty_id\", \"certainty_name\"])\n",
    "    image_attribute_labels = pd.read_csv(os.path.join(data_dir, 'attributes/image_attribute_labels.txt'),\n",
    "                                             # sep = ' ',\n",
    "                                             names=['image_id', 'attribute_id', 'is_present', 'certainty_id', 'time'],\n",
    "                                             delim_whitespace=True, usecols=range(5)\n",
    "                                            )    \n",
    "    with open(os.path.join(data_dir, 'llava_captions.json'), 'r') as f:\n",
    "        llava_captions = json.load(f)\n",
    "    return images, labels, classes,  bounding_boxes, parts, part_locs, parts_click_locs, attributes, certainties, image_attribute_labels, llava_captions\n",
    "# data_dir = '/content/drive/MyDrive/Bird-Species-Exploration-and-Retrieval/Dataset/CUB_200_2011'\n",
    "data_dir = './data'\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "parts_dir = os.path.join(data_dir, 'parts')\n",
    "\n",
    "images, labels_df, classes, bounding_boxes, parts, part_locs, parts_click_locs, attributes, certainties, image_attribute_labels, llava_captions = load_cub_dataset(data_dir)\n",
    "\n",
    "print(images.head())\n",
    "print(labels_df.head())\n",
    "print(classes.head())\n",
    "\n",
    "print(images.shape)\n",
    "print(labels_df.shape)\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11788, 512) (11788, 512)\n"
     ]
    }
   ],
   "source": [
    "clip_embeds_text = np.load('./data/clip_embeds_text.npy')\n",
    "clip_embeds_imgs = np.load('./data/clip_embeds_imgs.npy')\n",
    "print(clip_embeds_imgs.shape, clip_embeds_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeds = (clip_embeds_imgs + clip_embeds_text) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11788,)\n"
     ]
    }
   ],
   "source": [
    "labels = np.load('./data/labels.npy')\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\Anaconda\\envs\\AI_generic\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8637\n",
      "Test Accuracy: 0.7926\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(clip_embeds)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clip_embeds_text, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "text_clf = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "train_preds = text_clf.predict(X_train)\n",
    "test_preds = text_clf.predict(X_test)\n",
    "\n",
    "# Compute accuracy for each set\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "# Print results\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\Anaconda\\envs\\AI_generic\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9688\n",
      "Test Accuracy: 0.8075\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(clip_embeds)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clip_embeds, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_preds = clf.predict(X_train)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "# Compute accuracy for each set\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "# Print results\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\Anaconda\\envs\\AI_generic\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9945\n",
      "Test Accuracy: 0.7583\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(clip_embeds)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clip_embeds_imgs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "img_clf = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "img_clf.fit(X_train, y_train)\n",
    "\n",
    "train_preds = img_clf.predict(X_train)\n",
    "test_preds = img_clf.predict(X_test)\n",
    "\n",
    "# Compute accuracy for each set\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "# Print results\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_generic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

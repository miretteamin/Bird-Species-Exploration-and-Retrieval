{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Bird Species Classifier\n",
        "- In this notebook, we trained a classifier on top of CLIP.\n",
        "- Logistic regression, MLP and Random Forest classifiers used CLIP embeddings of bird images.\n",
        "- The classifier predicts the bird species based on the embeddings and evaluates its performance.\n",
        "- The trained model is saved for use in the bird species exploration and retrieval application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "fdWrMcC65bE4",
        "outputId": "b1446685-fc9a-4902-f178-12582999399b"
      },
      "outputs": [],
      "source": [
        "# !pip install ftfy regex tqdm\n",
        "# !pip install git+https://github.com/openai/CLIP.git\n",
        "# !pip install catboost\n",
        "# !pip install ipywidgets\n",
        "# !jupyter nbextension enable --py widgetsnbextension\n",
        "# import clip\n",
        "import joblib\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# !pip install numpy==1.23\n",
        "# from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VbF0gYgAp0ev",
        "outputId": "82eae998-cc88-4b0a-e321-2a3797ca341a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCbWigqu5bE6",
        "outputId": "d8b30add-40a0-4280-b91a-332d0400709e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\EGYPT\\AppData\\Local\\Temp\\ipykernel_6996\\3228900940.py:13: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  image_attribute_labels = pd.read_csv(os.path.join(data_dir, 'attributes/image_attribute_labels.txt'),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   image_id                                          file_path\n",
            "0         1  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
            "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
            "2         3  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
            "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
            "4         5  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
            "   image_id  class_id\n",
            "0         1         1\n",
            "1         2         1\n",
            "2         3         1\n",
            "3         4         1\n",
            "4         5         1\n",
            "   class_id                  class_name\n",
            "0         1  001.Black_footed_Albatross\n",
            "1         2        002.Laysan_Albatross\n",
            "2         3         003.Sooty_Albatross\n",
            "3         4       004.Groove_billed_Ani\n",
            "4         5          005.Crested_Auklet\n",
            "(11788, 2)\n",
            "(11788, 2)\n",
            "(200, 2)\n"
          ]
        }
      ],
      "source": [
        "# Load the CUB-200-2011 dataset\n",
        "data_dir = './data/CUB_200_2011'\n",
        "images_dir = os.path.join(data_dir, 'images')\n",
        "parts_dir = os.path.join(data_dir, 'parts')\n",
        "\n",
        "images, labels_df, classes, bounding_boxes, parts, part_locs, parts_click_locs, attributes, certainties, image_attribute_labels, llava_captions = load_cub_dataset(data_dir)\n",
        "\n",
        "print(images.head())\n",
        "print(labels_df.head())\n",
        "print(classes.head())\n",
        "\n",
        "print(images.shape)\n",
        "print(labels_df.shape)\n",
        "print(classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWlEOEfh5bE8",
        "outputId": "a1f10fa5-4b49-42cb-de28-8a950e9a7f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11788, 512) (11788, 512)\n"
          ]
        }
      ],
      "source": [
        "clip_embeds_imgs = np.load(os.path.join(data_dir, 'clip_embeds_imgs.npy'))\n",
        "clip_embeds_text = np.load(os.path.join(data_dir, 'clip_embeds_text.npy'))\n",
        "print(clip_embeds_imgs.shape, clip_embeds_text.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra9Z5TfO5bE8",
        "outputId": "5bd6fca4-100f-4502-d4d4-857d25110df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11788, 512)\n"
          ]
        }
      ],
      "source": [
        "clip_embeds = (clip_embeds_imgs + clip_embeds_text) / 2.0\n",
        "# clip_embeds = np.concatenate((clip_embeds_imgs, clip_embeds_text), axis=1)\n",
        "print(clip_embeds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DiXi6ba5bE9",
        "outputId": "dcd3a786-25e1-42b1-da10-f8250544c97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11788,)\n"
          ]
        }
      ],
      "source": [
        "labels = np.load(os.path.join(data_dir, 'labels.npy'))\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkWNAnClq8HQ"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFUn3Rx0q99A",
        "outputId": "c9846d67-3dd1-4a09-bf36-74a4592d1532"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:19<00:00, 17.8MiB/s]\n"
          ]
        }
      ],
      "source": [
        "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya1ewMHB5bE9"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3IpAZfLW_JG"
      },
      "source": [
        "## Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F9WFxHI5bE-",
        "outputId": "c2031fd7-db62-4a8e-b579-bd31f21228cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.9317\n",
            "Test Accuracy: 0.7867\n"
          ]
        }
      ],
      "source": [
        "dataset_size = len(clip_embeds)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(clip_embeds, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\", C=0.1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "train_preds = clf.predict(X_train)\n",
        "test_preds = clf.predict(X_test)\n",
        "\n",
        "train_acc = accuracy_score(y_train, train_preds)\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw2Wkt6cpTVY",
        "outputId": "7a40d521-3dd2-4c91-9b06-f0d42ff807a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Bird-Species-Exploration-and-Retrieval/Dataset/CUB_200_2011/classifier_concat.pkl']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(clf, os.path.join(data_dir, 'classifier.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EcWw_spj3oSq",
        "outputId": "447be0cb-f5c9-444f-dcd5-1e312cc705eb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Bird-Species-Exploration-and-Retrieval/Dataset/CUB_200_2011/images'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(data_dir, 'images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygoY5jTygch",
        "outputId": "a0445a48-5370-4f8f-b793-b87fa1d7e462"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.9123\n",
            "Test Accuracy: 0.7502\n"
          ]
        }
      ],
      "source": [
        "dataset_size = len(clip_embeds)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(clip_embeds_imgs, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "clf_img = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\", C=0.1)\n",
        "clf_img.fit(X_train, y_train)\n",
        "\n",
        "train_preds = clf_img.predict(X_train)\n",
        "test_preds = clf_img.predict(X_test)\n",
        "\n",
        "train_acc = accuracy_score(y_train, train_preds)\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdn8g6_ryswy",
        "outputId": "5731e938-5b37-4d54-d3e3-55bb93dbb5c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Bird-Species-Exploration-and-Retrieval/Dataset/CUB_200_2011/classifier_img.pkl']"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(clf_img, os.path.join(data_dir, 'classifier_img.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5TkNjFEy7fI",
        "outputId": "5d00e453-2a14-4c01-f095-c9759d370f5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.8670\n",
            "Test Accuracy: 0.7918\n"
          ]
        }
      ],
      "source": [
        "dataset_size = len(clip_embeds)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(clip_embeds_text, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "clf_text = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\")\n",
        "clf_text.fit(X_train, y_train)\n",
        "\n",
        "train_preds = clf_text.predict(X_train)\n",
        "test_preds = clf_text.predict(X_test)\n",
        "\n",
        "# Compute accuracy for each set\n",
        "train_acc = accuracy_score(y_train, train_preds)\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "# Print results\n",
        "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r91inhdPzAMY",
        "outputId": "2a4be7af-b406-42b7-e3d6-17ddd3f9ca9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Bird-Species-Exploration-and-Retrieval/Dataset/CUB_200_2011/classifier_text.pkl']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(clf_text, os.path.join(data_dir, 'classifier_text.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlBouEFvqDq3"
      },
      "outputs": [],
      "source": [
        "\n",
        "clf_path = os.path.join(data_dir, 'classifier.pkl')\n",
        "clf = joblib.load(clf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM07GsmvpxqX"
      },
      "outputs": [],
      "source": [
        "def baseline(img_path = None, text = None):\n",
        "    if img_path is None and text is None:\n",
        "      raise ValueError(\"Both img_path and text cannot be None\")\n",
        "    else:\n",
        "      if img_path is not None and text is None:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = clip_preprocess(img).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            features = clip_model.encode_image(img).cpu().numpy()\n",
        "            pred_class = clf_img.predict(features)\n",
        "            return pred_class[0]\n",
        "      elif img_path is None and text is not None:\n",
        "        with torch.no_grad():\n",
        "            features = clip_model.encode_text(clip.tokenize(text).to(device)).cpu().numpy()\n",
        "      else:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = clip_preprocess(img).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            features = clip_model.encode_image(img).cpu().numpy()\n",
        "            features += clip_model.encode_text(clip.tokenize(text).to(device)).cpu().numpy()\n",
        "            features /= 2.0\n",
        "      pred_class = clf.predict(features)\n",
        "      return pred_class[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKG5HxYIW8K9"
      },
      "source": [
        "## MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dPkWDMLiYGSO"
      },
      "outputs": [],
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=256, num_classes=200):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htr-1p6MW7r-"
      },
      "outputs": [],
      "source": [
        "dataset_size = len(clip_embeds)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(clip_embeds, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsVoTTfoV8Lu",
        "outputId": "938b730b-55dc-4b9d-ed65-6de07b4948f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - MLP Loss: 1195.4645\n",
            "Epoch 2/10 - MLP Loss: 554.5718\n",
            "Epoch 3/10 - MLP Loss: 371.9142\n",
            "Epoch 4/10 - MLP Loss: 301.1002\n",
            "Epoch 5/10 - MLP Loss: 262.7152\n",
            "Epoch 6/10 - MLP Loss: 234.3354\n",
            "Epoch 7/10 - MLP Loss: 214.1758\n",
            "Epoch 8/10 - MLP Loss: 196.3562\n",
            "Epoch 9/10 - MLP Loss: 182.9171\n",
            "Epoch 10/10 - MLP Loss: 171.4317\n",
            "MLP Train Accuracy: 0.8423\n",
            "MLP Test Accuracy: 0.7358\n"
          ]
        }
      ],
      "source": [
        "mlp_model = MLPClassifier(512, 200)\n",
        "batch_size = 32\n",
        "\n",
        "train_loader_mlp = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader_mlp = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    mlp_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader_mlp:\n",
        "        X_batch, y_batch = X_batch, y_batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = mlp_model(X_batch)\n",
        "        loss = criterion(outputs, y_batch-1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - MLP Loss: {total_loss:.4f}\")\n",
        "\n",
        "mlp_model.eval()\n",
        "\n",
        "y_pred_mlp = []\n",
        "y_true = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in train_loader_mlp:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = mlp_model(X_batch)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy() + 1\n",
        "        y_pred_mlp.extend(preds)\n",
        "        y_true.extend(y_batch.numpy())\n",
        "\n",
        "mlp_accuracy = accuracy_score(y_true, y_pred_mlp)\n",
        "print(f\"MLP Train Accuracy: {mlp_accuracy:.4f}\")\n",
        "\n",
        "y_pred_mlp_test = []\n",
        "y_true_test = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader_mlp:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = mlp_model(X_batch)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy() + 1\n",
        "        y_pred_mlp_test.extend(preds)\n",
        "        y_true_test.extend(y_batch.numpy())\n",
        "\n",
        "mlp_accuracy = accuracy_score(y_true_test, y_pred_mlp_test)\n",
        "print(f\"MLP Test Accuracy: {mlp_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGH8RtBQlY5n"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_size = len(clip_embeds)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(clip_embeds, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "_Gp3ioS3lan3",
        "outputId": "d93d3f57-3186-4b60-8d5f-c71d19e489f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.96\n",
            "Test Accuracy: 0.58\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize and train the Random Forest classifier\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,  # Limit the depth of the trees (Reg)\n",
        "    min_samples_split=10,  \n",
        "    min_samples_leaf=5,  \n",
        "    max_features='sqrt', \n",
        "    bootstrap=True,  \n",
        "    random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = clf.predict(X_train)\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f'Train Accuracy: {train_accuracy:.2f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
